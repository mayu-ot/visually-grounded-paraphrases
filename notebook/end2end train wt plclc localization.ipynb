{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fs1/mayu-ot/Experiments/loc_iparaphrasing\n"
     ]
    }
   ],
   "source": [
    "% cd /home/mayu-ot/durga/Experiments/loc_iparaphrasing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import initializers\n",
    "from chainercv.utils import read_image\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('func/nets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_rcnn import FasterRCNNExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(FullModel, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.frcnn = FasterRCNNExtractor(n_fg_class=20)\n",
    "            self.fc_l = L.Linear(None, 1000, initializers.HeNormal())\n",
    "            self.fc_v = L.Linear(None, 1000, initializers.HeNormal())\n",
    "            \n",
    "            # fusion net\n",
    "            self.fuse_l = L.Linear(None, 500, nobias=True, initialW=initializers.HeNormal())\n",
    "            self.fuse_v = L.Linear(None, 500, initialW=initializers.HeNormal())\n",
    "            \n",
    "            # classification net\n",
    "            self.mlp_0_l = L.Linear(None, 500, nobias=True, initialW=initializers.HeNormal())\n",
    "            self.mlp_0_r = L.Linear(None, 500, initialW=initializers.HeNormal())\n",
    "            self.mlp_1 = L.Linear(None, 2, initialW=initializers.LeCunNormal())\n",
    "            \n",
    "    def __call__(self, Xim, Xp1, Xp2, roi1, roi2, L):\n",
    "        roi_indices = self.xp.arange(len(Xim)).astype('f')\n",
    "        h_v1 = self.frcnn.extract(Xim, Xroi1, roi_indices)\n",
    "        h_v2 = self.frcnn.extract(Xim, Xroi2, roi_indices) # duplicate computation in the bottom layers\n",
    "        \n",
    "        \n",
    "        # fuse visual and language features\n",
    "        h_1 = F.relu(self.fuse_l(Xp1) + self.fuse_v(h_v1))\n",
    "        h_2 = F.relu(self.fuse_l(Xp2) + self.fuse_v(h_v2))\n",
    "        \n",
    "        # classification -> VGP or non-VGP\n",
    "        h = F.relu(self.mlp_0_l(h_1) + self.mlp_0_r(h_2)) # what will happen about order variance?\n",
    "        h = F.mlp_1(h)\n",
    "        loss = F.softmax_cross_entropy(h, L)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('script/training/')\n",
    "from train import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Todo:\n",
    "chainer dataset実装\n",
    "(参考）script/training/train.py RegionEntityDatasetBase, EntityDatasetPhraseFeat あたりに似たようなものがある\n",
    "get_roiとget_labelが未実装\n",
    "\n",
    "phraseに対応するroiの取り方\n",
    "データのあるファイル\n",
    "- data/pl-clc/phrase_pair_wt_plclcbbox_<split>.csv\n",
    "- data/region_feat/roi/full_<split>.h5\n",
    "\n",
    "例）validation setのi番目のフレーズペアに対応するroi座標取得\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/pl-clc/phrase_pair_wt_plclcbbox_val.csv')\n",
    "h5file = tables.open_file('data/region_feat/roi/full_val.h5')\n",
    "\n",
    "row = df.iloc[0]\n",
    "rindex_1, rindex_2 = row[['roi1', 'roi2']]\n",
    "\n",
    "node = h5file.get_node('/', str(row['image']))\n",
    "roi1 = node[rindex_1]\n",
    "roi2 = node[rindex_2] # xmin, ymin, xmax, ymax\n",
    "\n",
    "* faster rcnnは(ymin, xmin, ymax, xmax)の形式で受け取るので変換が必要\n",
    "'''\n",
    "\n",
    "class DataPbd(chainer.dataset.DatasetMixin):\n",
    "    \n",
    "    def __init__(self, phrase_feature_file, unique_phrase_file):\n",
    "        phrase2id_dict = defaultdict(lambda: -1)\n",
    "        with open(unique_phrase_file) as f:\n",
    "            for i, line in enumerate(f):\n",
    "                phrase2id_dict[line.rstrip()] = i\n",
    "        \n",
    "        self._p2i_dict = phrase2id_dict\n",
    "        self._feat = np.load(phrase_feature_file).astype(np.float32)\n",
    "    \n",
    "    def get_roi(self, i):\n",
    "        # not implemented\n",
    "        # input\n",
    "        # i: dataset index\n",
    "        # return\n",
    "        # roi1: roi for phrase 1\n",
    "        # roi2: roi for phrase 2\n",
    "        \n",
    "        return roi1, roi2\n",
    "    \n",
    "    def get_label(self, i):\n",
    "        # not implemented\n",
    "        # input\n",
    "        # i: dataset index\n",
    "        # return\n",
    "        # l: binary label. 1 if phrases are VGP, otherwise 0\n",
    "        return l\n",
    "    \n",
    "    def get_example(self, i):\n",
    "        img = read_image(self.root + self.image[i], color=True)\n",
    "        \n",
    "        # get roi\n",
    "        roi1, roi2 = self.get_roi(i)\n",
    "        \n",
    "        # preprocess image and roi\n",
    "        x = model.prepare(img)\n",
    "        scale = x.shape[-1] * 1. / img.shape[-1]\n",
    "        roi1 = roi1 * scale\n",
    "        roi2 = roi2 * scale\n",
    "        \n",
    "        # get phrase features\n",
    "        p1 = self._feat[self._p2i_dict[self._phrase1[i]]]\n",
    "        p2 = self._feat[self._p2i_dict[self._phrase2[i]]]\n",
    "        \n",
    "        # get label (VGP or non-VGP)\n",
    "        l = self.get_label(i)\n",
    "        \n",
    "        return img, p1, p2, roi1, roi2, l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
