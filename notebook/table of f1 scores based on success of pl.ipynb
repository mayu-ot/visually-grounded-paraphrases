{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute f1 scores when:\n",
    "\n",
    "- two phrases are correctly localized\n",
    "- only one phrases are correctly localized\n",
    "- both failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fs1/mayu-ot/Experiments/loc_iparaphrasing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayu-ot/miniconda3/envs/py36chainer/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/mayu-ot/miniconda3/envs/py36chainer/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "% cd /home/mayu-ot/durga/Experiments/loc_iparaphrasing/\n",
    "\n",
    "from chainercv.utils import bbox_iou, non_maximum_suppression\n",
    "import chainer\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import tables\n",
    "from chainer.dataset.convert import concat_examples\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from func.datasets.datasets import get_agg_roi_df\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.html.widgets import IntProgress\n",
    "from IPython.display import display\n",
    "from nltk.metrics import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func.datasets.datasets import BBoxDataset, PLCLCBBoxDataset, DDPNBBoxDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar(q, targ):\n",
    "    best_d = np.inf\n",
    "    for x in targ:\n",
    "        d = edit_distance(q, x)\n",
    "        if d < best_d:\n",
    "            best_d = d\n",
    "            res = x\n",
    "        if best_d == 0:\n",
    "            break\n",
    "    return res\n",
    "\n",
    "def lget_bbox(df, img_id, phr):\n",
    "    item = df[(df.image == img_id) & (df.phrase == phr)]\n",
    "    if len(item) == 0:\n",
    "        phrases = df[(df.image == img_id)].phrase.tolist()\n",
    "        phr_ = get_most_similar(phr, phrases)\n",
    "        item = df[(df.image == img_id) & (df.phrase == phr_)]\n",
    "        \n",
    "    roi = item[['ymin', 'xmin', 'ymax', 'xmax']].values\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PLCLCBBoxDataset('test')\n",
    "plclc_df = data.df\n",
    "data = BBoxDataset('test')\n",
    "gt_df = data.df.reset_index(level=[0,1])\n",
    "gt_df = gt_df.rename(columns={'org_phrase': 'phrase'})\n",
    "\n",
    "data = DDPNBBoxDataset('test')\n",
    "ddpn_df = data.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6553edb3a05242608a45a76078bf474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=81285)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/phrase_pair_test.csv')\n",
    "ip = IntProgress(min=0, max=len(df))\n",
    "display(ip)\n",
    "\n",
    "plclc_ious1 = []\n",
    "plclc_ious2 = []\n",
    "ddpn_ious1 = []\n",
    "ddpn_ious2 = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    im_id, phr1, phr2 = row[['image', 'original_phrase1', 'original_phrase2']]\n",
    "    \n",
    "    gt_bbox1 = lget_bbox(gt_df, im_id, phr1)\n",
    "    gt_bbox2 = lget_bbox(gt_df, im_id, phr2)\n",
    "    \n",
    "    p_bbox1 = lget_bbox(plclc_df, im_id, phr1)\n",
    "    p_bbox2 = lget_bbox(plclc_df, im_id, phr2)\n",
    "    \n",
    "    d_bbox1 = lget_bbox(ddpn_df, im_id, phr1.lower())\n",
    "    d_bbox2 = lget_bbox(ddpn_df, im_id, phr2.lower())\n",
    "    \n",
    "    plclc_iou1 = bbox_iou(p_bbox1, gt_bbox1)\n",
    "    plclc_iou2 = bbox_iou(p_bbox2, gt_bbox2)\n",
    "    \n",
    "    plclc_ious1.append(plclc_iou1[0])\n",
    "    plclc_ious2.append(plclc_iou2[0])\n",
    "    \n",
    "    ddpn_iou1 = bbox_iou(d_bbox1, gt_bbox1)\n",
    "    ddpn_iou2 = bbox_iou(d_bbox2, gt_bbox2)\n",
    "    \n",
    "    ddpn_ious1.append(ddpn_iou1[0])\n",
    "    ddpn_ious2.append(ddpn_iou2[0])\n",
    "    \n",
    "    ip.value = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plclc_ious1 = np.asarray(plclc_ious1).ravel()\n",
    "plclc_ious2 = np.asarray(plclc_ious2).ravel()\n",
    "\n",
    "ddpn_ious1 = np.asarray(ddpn_ious1).ravel()\n",
    "ddpn_ious2 = np.asarray(ddpn_ious2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both success: 0.3\n",
      "at least one fail: 0.7\n"
     ]
    }
   ],
   "source": [
    "# both success\n",
    "both_success = np.logical_and((plclc_ious1 >= .5), (plclc_ious2 >= .5))\n",
    "\n",
    "# at least one fail\n",
    "fail = np.logical_or((plclc_ious1 < .5), (plclc_ious2 < .5))\n",
    "\n",
    "print('both success: %.1f' % (both_success.sum()/ both_success.size))\n",
    "print('at least one fail: %.1f' % (fail.sum()/ both_success.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: f1 0.58, prec 0.52, rec 0.65\n",
      "overall: f1 0.85, prec 0.83, rec 0.87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f:f1</th>\n",
       "      <th>f:prec</th>\n",
       "      <th>f:rec</th>\n",
       "      <th>method</th>\n",
       "      <th>s:f1</th>\n",
       "      <th>s:prec</th>\n",
       "      <th>s:rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.526287</td>\n",
       "      <td>27.002181</td>\n",
       "      <td>37.871503</td>\n",
       "      <td>vis+plclc</td>\n",
       "      <td>79.284538</td>\n",
       "      <td>74.208462</td>\n",
       "      <td>85.106041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.666667</td>\n",
       "      <td>72.292994</td>\n",
       "      <td>79.370629</td>\n",
       "      <td>vis+lng+plclc+mult</td>\n",
       "      <td>92.359551</td>\n",
       "      <td>92.270686</td>\n",
       "      <td>92.448586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f:f1     f:prec      f:rec              method       s:f1     s:prec  \\\n",
       "0  31.526287  27.002181  37.871503           vis+plclc  79.284538  74.208462   \n",
       "1  75.666667  72.292994  79.370629  vis+lng+plclc+mult  92.359551  92.270686   \n",
       "\n",
       "       s:rec  \n",
       "0  85.106041  \n",
       "1  92.448586  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLCLC\n",
    "files = [\n",
    "    'bo_out/vis+plclc/25-20181111-060511/res_test.csv',\n",
    "    'bo_out/vis+lng+plclc+mult/17-20181108-050238/res_test.csv'\n",
    "]\n",
    "\n",
    "results = {'method': [], 's:f1':[], 's:prec':[], 's:rec':[], 'f:f1':[], 'f:prec':[], 'f:rec':[]}\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    ypred = df.ypred.values\n",
    "    ytrue = df.ytrue.values\n",
    "    \n",
    "    results['method'].append(f.split('/')[1])\n",
    "\n",
    "    f1 = f1_score(ytrue[both_success], ypred[both_success])\n",
    "    prec = precision_score(ytrue[both_success], ypred[both_success])\n",
    "    rec = recall_score(ytrue[both_success], ypred[both_success])\n",
    "    \n",
    "    results['s:f1'].append(f1*100)\n",
    "    results['s:prec'].append(prec*100)\n",
    "    results['s:rec'].append(rec*100)    \n",
    "\n",
    "    f1 = f1_score(ytrue[fail], ypred[fail])\n",
    "    prec = precision_score(ytrue[fail], ypred[fail])\n",
    "    rec = recall_score(ytrue[fail], ypred[fail])\n",
    "    \n",
    "    results['f:f1'].append(f1*100)\n",
    "    results['f:prec'].append(prec*100)\n",
    "    results['f:rec'].append(rec*100)\n",
    "\n",
    "    f1 = f1_score(ytrue, ypred)\n",
    "    prec = precision_score(ytrue, ypred)\n",
    "    rec = recall_score(ytrue, ypred)\n",
    "    print('overall: f1 %.2f, prec %.2f, rec %.2f' % (f1, prec, rec))\n",
    "    \n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both success: f1 0.87, prec 0.86, rec 0.89\n",
      "one success: f1 0.54, prec 0.46, rec 0.65\n",
      "both fail: f1 0.80, prec 0.82, rec 0.79\n",
      "overall: f1 0.85, prec 0.83, rec 0.87\n"
     ]
    }
   ],
   "source": [
    "# Ours with plclc\n",
    "df = pd.read_csv('bo_out/vis+lng+plclc+mult/17-20181108-050238/res_test.csv')\n",
    "ypred = df.ypred.values\n",
    "ytrue = df.ytrue.values\n",
    "\n",
    "f1 = f1_score(ytrue[both_success], ypred[both_success])\n",
    "prec = precision_score(ytrue[both_success], ypred[both_success])\n",
    "rec = recall_score(ytrue[both_success], ypred[both_success])\n",
    "print('both success: f1 %.2f, prec %.2f, rec %.2f' % (f1, prec, rec))\n",
    "\n",
    "f1 = f1_score(ytrue[one_success], ypred[one_success])\n",
    "prec = precision_score(ytrue[one_success], ypred[one_success])\n",
    "rec = recall_score(ytrue[one_success], ypred[one_success])\n",
    "print('one success: f1 %.2f, prec %.2f, rec %.2f' % (f1, prec, rec))\n",
    "\n",
    "f1 = f1_score(ytrue[both_fail], ypred[both_fail])\n",
    "prec = precision_score(ytrue[both_fail], ypred[both_fail])\n",
    "rec = recall_score(ytrue[both_fail], ypred[both_fail])\n",
    "print('both fail: f1 %.2f, prec %.2f, rec %.2f' % (f1, prec, rec))\n",
    "\n",
    "f1 = f1_score(ytrue, ypred)\n",
    "prec = precision_score(ytrue, ypred)\n",
    "rec = recall_score(ytrue, ypred)\n",
    "print('overall: f1 %.2f, prec %.2f, rec %.2f' % (f1, prec, rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both success: 0.7\n",
      "at least one fail: 0.3\n"
     ]
    }
   ],
   "source": [
    "# both success\n",
    "both_success = np.logical_and((ddpn_ious1 >= .5), (ddpn_ious2 >= .5))\n",
    "\n",
    "# at least one fail\n",
    "fail = np.logical_or((ddpn_ious1 < .5), (ddpn_ious2 < .5))\n",
    "\n",
    "print('both success: %.1f' % (both_success.sum()/ both_success.size))\n",
    "print('at least one fail: %.1f' % (fail.sum()/ both_success.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both_success: 0.17\n",
      "at least one fail: 0.06\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/phrase_pair_test.csv', index_col=0)\n",
    "labels = df.loc[both_success, ['ytrue']]\n",
    "print('both_success: %.2f' % (sum(labels.values)/len(labels)))\n",
    "labels = df.loc[fail, ['ytrue']]\n",
    "print('at least one fail: %.2f' % (sum(labels.values)/len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: f1 0.66, prec 0.61, rec 0.73\n",
      "overall: f1 0.86, prec 0.86, rec 0.87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f:f1</th>\n",
       "      <th>f:prec</th>\n",
       "      <th>f:rec</th>\n",
       "      <th>method</th>\n",
       "      <th>s:f1</th>\n",
       "      <th>s:prec</th>\n",
       "      <th>s:rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.781872</td>\n",
       "      <td>45.621019</td>\n",
       "      <td>62.609266</td>\n",
       "      <td>vis_ddpn</td>\n",
       "      <td>77.820104</td>\n",
       "      <td>75.38786</td>\n",
       "      <td>80.414524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.181623</td>\n",
       "      <td>76.741739</td>\n",
       "      <td>79.676573</td>\n",
       "      <td>vis+lng+ddpn+mult</td>\n",
       "      <td>92.694688</td>\n",
       "      <td>92.73195</td>\n",
       "      <td>92.657455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f:f1     f:prec      f:rec             method       s:f1    s:prec  \\\n",
       "0  52.781872  45.621019  62.609266           vis_ddpn  77.820104  75.38786   \n",
       "1  78.181623  76.741739  79.676573  vis+lng+ddpn+mult  92.694688  92.73195   \n",
       "\n",
       "       s:rec  \n",
       "0  80.414524  \n",
       "1  92.657455  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DDPN\n",
    "files = [\n",
    "    'bo_out/vis_ddpn/7-20181107-221739/res_test.csv',\n",
    "    'bo_out/vis+lng+ddpn+mult/18-20181108-015934/res_test.csv'\n",
    "]\n",
    "\n",
    "results = {'method': [], 's:f1':[], 's:prec':[], 's:rec':[], 'f:f1':[], 'f:prec':[], 'f:rec':[]}\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    ypred = df.ypred.values\n",
    "    ytrue = df.ytrue.values\n",
    "    \n",
    "    results['method'].append(f.split('/')[1])\n",
    "\n",
    "    f1 = f1_score(ytrue[both_success], ypred[both_success])\n",
    "    prec = precision_score(ytrue[both_success], ypred[both_success])\n",
    "    rec = recall_score(ytrue[both_success], ypred[both_success])\n",
    "    \n",
    "    results['s:f1'].append(f1*100)\n",
    "    results['s:prec'].append(prec*100)\n",
    "    results['s:rec'].append(rec*100)    \n",
    "\n",
    "    f1 = f1_score(ytrue[fail], ypred[fail])\n",
    "    prec = precision_score(ytrue[fail], ypred[fail])\n",
    "    rec = recall_score(ytrue[fail], ypred[fail])\n",
    "    \n",
    "    results['f:f1'].append(f1*100)\n",
    "    results['f:prec'].append(prec*100)\n",
    "    results['f:rec'].append(rec*100)\n",
    "\n",
    "    f1 = f1_score(ytrue, ypred)\n",
    "    prec = precision_score(ytrue, ypred)\n",
    "    rec = recall_score(ytrue, ypred)\n",
    "    print('overall: f1 %.2f, prec %.2f, rec %.2f' % (f1, prec, rec))\n",
    "    \n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
